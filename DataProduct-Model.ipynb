{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smart Detection of Bot/Malware Generated Network Traffic  (using the CTU-13 dataset): ML Model\n",
    "\n",
    "Malware traffic is often hard to detect as it uses real users' PC or browsers in order to generate fraudulent activity and Spam. This notebook shows how to build a simple supervised model that will be trained to detect malware based traffic in a network traffic log or capture. When the model flags an IP as generating malware based spam and fraudulent activity  it can be listed for quarantine or further analysis. \n",
    "\n",
    "##### This notebook first prepares and process the features, and  then build and evaluate a sequential neural network and a gradient boosting trees algorithms. The third file in this series implement this in Spark\n",
    "\n",
    "\n",
    "About the Data Set\n",
    "The Dataset used here is part of a larger dataset (named CTU-13) which records 4 hours of network traffic in a computer network of a university department in the CTU University, Czech Republic. The researchers that created the dataset infected one of the computers in the network in a malware that generates ClickFraud and Spam activity. The traffic was recorded by a traffic analytics tool which captured malware-based activity generated by the infected PC in addition to normal traffic. Since the infected computer is known, the data is labeled and the purpose of the project is to present a supervised classification model.\n",
    "\n",
    "https://github.com/Hurence/logisland-flow-analytics-ml-jobs/blob/master/README.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(r'C:\\Users\\alon\\OneDrive\\Documents\\Coursera-ML\\Sample2Capture.csv')\n",
    "#Remove uninteresting data based on domain knowledge\n",
    "\n",
    "# we know the infected system IP addr so lets add it \n",
    "infected_addr = \"147.32.84.165\"\n",
    "df_raw[\"Bot\"] = np.where(df_raw['SrcAddr'] == infected_addr, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Features for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alon\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\alon\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#df_raw = df_raw.sample(frac=0.75)\n",
    "\n",
    "#Fill null values\n",
    "df_raw[\"sTos\"] = df_raw[\"sTos\"].fillna(value=-1)\n",
    "df_raw[\"dTos\"] = df_raw[\"dTos\"].fillna(value=-1)\n",
    "\n",
    "# define processing functions\n",
    "def encode_field(df,field):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    return  encoder.fit_transform(df[field])\n",
    "\n",
    "def hot_encode(df, feature):\n",
    "    return pd.get_dummies(\n",
    "            encode_field(df_raw, feature), prefix=feature + \"_\", drop_first=True)\n",
    "\n",
    "def group_less_frequent_values(df, feature, min_prc):\n",
    "    categories = df[feature].value_counts()    \n",
    "    for category in categories.index:                \n",
    "        # how many times this category shows in the DS?\n",
    "        freq = categories[category]        \n",
    "        # if less than what we want (min_prc)\n",
    "        if(freq < min_prc):\n",
    "            new_val = \"Q\" if df[feature].dtypes == object else 99\n",
    "            df.loc[df[feature] == category, feature] = new_val\n",
    " \n",
    "# process the categorical features        \n",
    "categorical_features = ['State','Proto','Dir', 'dTos','sTos']\n",
    "# classes that are not frequent in the data (less than 1%) will be grouped. \n",
    "one_p = 0.01 * len(df_raw.index) \n",
    "#loog through the categorical \n",
    "for feature in categorical_features:\n",
    "    #group the less frequent ones\n",
    "    group_less_frequent_values(df_raw, feature, one_p)\n",
    "    #index and then hot encode\n",
    "    df_raw = pd.concat([df_raw, hot_encode(df_raw,feature)],axis=1)\n",
    "    \n",
    "##standardizing numerical feature\n",
    "df_raw[['Dur', 'TotPkts','SrcBytes']] = StandardScaler().fit_transform(df_raw[['Dur', 'TotPkts','SrcBytes']])\n",
    "\n",
    "## remove what we dont need \n",
    "df_raw = df_raw.drop(columns=categorical_features)\n",
    "df_raw = df_raw.drop(columns=['SrcAddr','DstAddr','Label','TotBytes','Sport','Dport','StartTime'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dur</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Bot</th>\n",
       "      <th>State__1</th>\n",
       "      <th>State__2</th>\n",
       "      <th>State__3</th>\n",
       "      <th>State__4</th>\n",
       "      <th>State__5</th>\n",
       "      <th>State__6</th>\n",
       "      <th>Proto__1</th>\n",
       "      <th>Proto__2</th>\n",
       "      <th>Proto__3</th>\n",
       "      <th>Dir__1</th>\n",
       "      <th>Dir__2</th>\n",
       "      <th>dTos__1</th>\n",
       "      <th>dTos__2</th>\n",
       "      <th>sTos__1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.475694</td>\n",
       "      <td>-0.005090</td>\n",
       "      <td>-0.005682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.475708</td>\n",
       "      <td>-0.005550</td>\n",
       "      <td>-0.005064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.475662</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>-0.002179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.476096</td>\n",
       "      <td>-0.009234</td>\n",
       "      <td>-0.010388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.476095</td>\n",
       "      <td>-0.009234</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dur   TotPkts  SrcBytes  Bot  State__1  State__2  State__3  State__4  \\\n",
       "0 -0.475694 -0.005090 -0.005682    0         1         0         0         0   \n",
       "1 -0.475708 -0.005550 -0.005064    0         1         0         0         0   \n",
       "2 -0.475662 -0.006471 -0.002179    0         0         0         1         0   \n",
       "3 -0.476096 -0.009234 -0.010388    0         0         0         0         0   \n",
       "4 -0.476095 -0.009234 -0.007950    0         0         0         0         0   \n",
       "\n",
       "   State__5  State__6  Proto__1  Proto__2  Proto__3  Dir__1  Dir__2  dTos__1  \\\n",
       "0         0         0         0         1         0       0       0        1   \n",
       "1         0         0         0         1         0       0       0        1   \n",
       "2         0         0         0         1         0       0       0        1   \n",
       "3         0         0         0         0         1       1       0        1   \n",
       "4         0         0         0         0         1       1       0        1   \n",
       "\n",
       "   dTos__2  sTos__1  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        0  \n",
       "4        0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_raw.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the data and prepare test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw\n",
    "\n",
    "set_train, set_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "#balance the training set\n",
    "bot_data = set_train[set_train['Bot'] == 1]\n",
    "normal_data = set_train[set_train['Bot'] == 0]\n",
    "normal_data_downsampled = normal_data.sample(n=len(bot_data.index))\n",
    "set_train = pd.concat([bot_data,normal_data_downsampled])\n",
    "\n",
    "col_list = list(df.columns)\n",
    "col_list.remove(\"Bot\")\n",
    "x_train = set_train.loc[:,col_list]\n",
    "x_test  = set_test.loc[:, col_list]\n",
    "y_train = set_train.loc[:,'Bot']\n",
    "y_test = set_test.loc[:,'Bot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function that will print the accuracy of our model by printing confusion.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perc(tn,tp,fn,fp):\n",
    "    actual_true = tp + fn\n",
    "    pr_t = round((tp / actual_true * 100), 2)\n",
    "    actual_false = tn + fp\n",
    "    pr_f = round((fp / actual_false * 100), 2)\n",
    "    print(f\"{tp}/{actual_true}({pr_t}%) were correctly identified as bots\")\n",
    "    print(f\"{fp}/{actual_false} ({pr_f}%) were wrongly identified as bots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and evalutate a gradient boosting algoritm (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.26%\n",
      "[[68259  5725]\n",
      " [   46   513]]\n",
      "\n",
      " ********************************** \n",
      "\n",
      "513/559(91.77%) were correctly identified as bots\n",
      "5725/73984 (7.74%) were wrongly identified as bots\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"\\n ********************************** \\n\")\n",
    "\n",
    "tn = cm[0,0]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "tp = cm[1,1]\n",
    "print_perc(tn,tp,fn,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 513/559(91.77%) were correctly identified as bots\n",
    "##### 5725/73984 (7.74%) were wrongly identified as bots\n",
    "#### The results are quite nice. Now let's compare it to a deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to a deep learning algorithm (Sequential NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4258/4258 [==============================] - 1s 147us/step - loss: 0.6898 - acc: 0.6134\n",
      "Epoch 2/100\n",
      "4258/4258 [==============================] - 0s 26us/step - loss: 0.6407 - acc: 0.8687\n",
      "Epoch 3/100\n",
      "4258/4258 [==============================] - 0s 26us/step - loss: 0.5044 - acc: 0.8767\n",
      "Epoch 4/100\n",
      "4258/4258 [==============================] - 0s 29us/step - loss: 0.3846 - acc: 0.8783\n",
      "Epoch 5/100\n",
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.3280 - acc: 0.8783\n",
      "Epoch 6/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.3116 - acc: 0.8793\n",
      "Epoch 7/100\n",
      "4258/4258 [==============================] - 0s 25us/step - loss: 0.3077 - acc: 0.8788\n",
      "Epoch 8/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.3056 - acc: 0.8798\n",
      "Epoch 9/100\n",
      "4258/4258 [==============================] - 0s 39us/step - loss: 0.3044 - acc: 0.8802\n",
      "Epoch 10/100\n",
      "4258/4258 [==============================] - 0s 41us/step - loss: 0.3035 - acc: 0.8798\n",
      "Epoch 11/100\n",
      "4258/4258 [==============================] - 0s 72us/step - loss: 0.3026 - acc: 0.8793\n",
      "Epoch 12/100\n",
      "4258/4258 [==============================] - 0s 52us/step - loss: 0.3018 - acc: 0.8793\n",
      "Epoch 13/100\n",
      "4258/4258 [==============================] - 0s 30us/step - loss: 0.3012 - acc: 0.8795\n",
      "Epoch 14/100\n",
      "4258/4258 [==============================] - 0s 39us/step - loss: 0.3004 - acc: 0.8793\n",
      "Epoch 15/100\n",
      "4258/4258 [==============================] - 0s 35us/step - loss: 0.3003 - acc: 0.8793\n",
      "Epoch 16/100\n",
      "4258/4258 [==============================] - 0s 36us/step - loss: 0.2996 - acc: 0.8791\n",
      "Epoch 17/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.2996 - acc: 0.8788\n",
      "Epoch 18/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2992 - acc: 0.8793\n",
      "Epoch 19/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2985 - acc: 0.8793\n",
      "Epoch 20/100\n",
      "4258/4258 [==============================] - 0s 43us/step - loss: 0.2983 - acc: 0.8798\n",
      "Epoch 21/100\n",
      "4258/4258 [==============================] - 0s 51us/step - loss: 0.2979 - acc: 0.8798\n",
      "Epoch 22/100\n",
      "4258/4258 [==============================] - 0s 60us/step - loss: 0.2974 - acc: 0.8795\n",
      "Epoch 23/100\n",
      "4258/4258 [==============================] - 0s 53us/step - loss: 0.2971 - acc: 0.8800: 0s - loss: 0.2971 - acc: 0.880\n",
      "Epoch 24/100\n",
      "4258/4258 [==============================] - 0s 45us/step - loss: 0.2969 - acc: 0.8800\n",
      "Epoch 25/100\n",
      "4258/4258 [==============================] - 0s 51us/step - loss: 0.2967 - acc: 0.8800\n",
      "Epoch 26/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2964 - acc: 0.8788\n",
      "Epoch 27/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2961 - acc: 0.8802\n",
      "Epoch 28/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2959 - acc: 0.8807\n",
      "Epoch 29/100\n",
      "4258/4258 [==============================] - 0s 26us/step - loss: 0.2955 - acc: 0.8798\n",
      "Epoch 30/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2954 - acc: 0.8802\n",
      "Epoch 31/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.2954 - acc: 0.8809\n",
      "Epoch 32/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.2952 - acc: 0.8795\n",
      "Epoch 33/100\n",
      "4258/4258 [==============================] - 0s 64us/step - loss: 0.2947 - acc: 0.8812\n",
      "Epoch 34/100\n",
      "4258/4258 [==============================] - 0s 46us/step - loss: 0.2948 - acc: 0.8798\n",
      "Epoch 35/100\n",
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.2947 - acc: 0.8793\n",
      "Epoch 36/100\n",
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.2946 - acc: 0.8793\n",
      "Epoch 37/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2941 - acc: 0.8800\n",
      "Epoch 38/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2940 - acc: 0.8812\n",
      "Epoch 39/100\n",
      "4258/4258 [==============================] - 0s 25us/step - loss: 0.2937 - acc: 0.8814\n",
      "Epoch 40/100\n",
      "4258/4258 [==============================] - 0s 35us/step - loss: 0.2937 - acc: 0.8814\n",
      "Epoch 41/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2935 - acc: 0.8809\n",
      "Epoch 42/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2938 - acc: 0.8807\n",
      "Epoch 43/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2935 - acc: 0.8795\n",
      "Epoch 44/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2932 - acc: 0.8800\n",
      "Epoch 45/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2933 - acc: 0.8807\n",
      "Epoch 46/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2934 - acc: 0.8816\n",
      "Epoch 47/100\n",
      "4258/4258 [==============================] - 0s 51us/step - loss: 0.2932 - acc: 0.8800\n",
      "Epoch 48/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2932 - acc: 0.8800\n",
      "Epoch 49/100\n",
      "4258/4258 [==============================] - 0s 24us/step - loss: 0.2930 - acc: 0.8798\n",
      "Epoch 50/100\n",
      "4258/4258 [==============================] - 0s 30us/step - loss: 0.2929 - acc: 0.8805\n",
      "Epoch 51/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2929 - acc: 0.8793\n",
      "Epoch 52/100\n",
      "4258/4258 [==============================] - 0s 35us/step - loss: 0.2926 - acc: 0.8798\n",
      "Epoch 53/100\n",
      "4258/4258 [==============================] - 0s 30us/step - loss: 0.2927 - acc: 0.8809\n",
      "Epoch 54/100\n",
      "4258/4258 [==============================] - 0s 27us/step - loss: 0.2924 - acc: 0.8802\n",
      "Epoch 55/100\n",
      "4258/4258 [==============================] - 0s 26us/step - loss: 0.2924 - acc: 0.8816\n",
      "Epoch 56/100\n",
      "4258/4258 [==============================] - 0s 38us/step - loss: 0.2925 - acc: 0.8809\n",
      "Epoch 57/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2924 - acc: 0.8791\n",
      "Epoch 58/100\n",
      "4258/4258 [==============================] - 0s 29us/step - loss: 0.2923 - acc: 0.8821\n",
      "Epoch 59/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2922 - acc: 0.8809\n",
      "Epoch 60/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2921 - acc: 0.8812\n",
      "Epoch 61/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2921 - acc: 0.8821\n",
      "Epoch 62/100\n",
      "4258/4258 [==============================] - 0s 30us/step - loss: 0.2920 - acc: 0.8812\n",
      "Epoch 63/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.2918 - acc: 0.8816\n",
      "Epoch 64/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2921 - acc: 0.8821\n",
      "Epoch 65/100\n",
      "4258/4258 [==============================] - 0s 35us/step - loss: 0.2923 - acc: 0.8807\n",
      "Epoch 66/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2923 - acc: 0.8819\n",
      "Epoch 67/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2917 - acc: 0.8819\n",
      "Epoch 68/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2917 - acc: 0.8816\n",
      "Epoch 69/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2921 - acc: 0.8809\n",
      "Epoch 70/100\n",
      "4258/4258 [==============================] - 0s 33us/step - loss: 0.2918 - acc: 0.8809\n",
      "Epoch 71/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2915 - acc: 0.8816\n",
      "Epoch 72/100\n",
      "4258/4258 [==============================] - 0s 39us/step - loss: 0.2917 - acc: 0.8807\n",
      "Epoch 73/100\n",
      "4258/4258 [==============================] - 0s 30us/step - loss: 0.2917 - acc: 0.8802\n",
      "Epoch 74/100\n",
      "4258/4258 [==============================] - 0s 32us/step - loss: 0.2915 - acc: 0.8805\n",
      "Epoch 75/100\n",
      "4258/4258 [==============================] - 0s 31us/step - loss: 0.2916 - acc: 0.8805\n",
      "Epoch 76/100\n",
      "4258/4258 [==============================] - 0s 25us/step - loss: 0.2913 - acc: 0.8819\n",
      "Epoch 77/100\n",
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.2913 - acc: 0.8809\n",
      "Epoch 78/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2914 - acc: 0.8807\n",
      "Epoch 79/100\n",
      "4258/4258 [==============================] - 0s 34us/step - loss: 0.2915 - acc: 0.8802\n",
      "Epoch 80/100\n",
      "4258/4258 [==============================] - 0s 41us/step - loss: 0.2914 - acc: 0.8809\n",
      "Epoch 81/100\n",
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.2912 - acc: 0.8823\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4258/4258 [==============================] - 0s 37us/step - loss: 0.2915 - acc: 0.8809\n",
      "Epoch 83/100\n",
      "4258/4258 [==============================] - 0s 41us/step - loss: 0.2912 - acc: 0.8814\n",
      "Epoch 84/100\n",
      "4258/4258 [==============================] - 0s 52us/step - loss: 0.2912 - acc: 0.8821: 0s - loss: 0.2815 - acc: 0.8\n",
      "Epoch 85/100\n",
      "4258/4258 [==============================] - 0s 41us/step - loss: 0.2910 - acc: 0.8821\n",
      "Epoch 86/100\n",
      "4258/4258 [==============================] - 0s 42us/step - loss: 0.2912 - acc: 0.8819\n",
      "Epoch 87/100\n",
      "4258/4258 [==============================] - 0s 50us/step - loss: 0.2910 - acc: 0.8814\n",
      "Epoch 88/100\n",
      "4258/4258 [==============================] - 0s 38us/step - loss: 0.2913 - acc: 0.8814\n",
      "Epoch 89/100\n",
      "4258/4258 [==============================] - 0s 49us/step - loss: 0.2907 - acc: 0.8805\n",
      "Epoch 90/100\n",
      "4258/4258 [==============================] - 0s 46us/step - loss: 0.2913 - acc: 0.8821\n",
      "Epoch 91/100\n",
      "4258/4258 [==============================] - 0s 57us/step - loss: 0.2909 - acc: 0.8805\n",
      "Epoch 92/100\n",
      "4258/4258 [==============================] - 0s 52us/step - loss: 0.2910 - acc: 0.8819\n",
      "Epoch 93/100\n",
      "4258/4258 [==============================] - 0s 66us/step - loss: 0.2909 - acc: 0.8821\n",
      "Epoch 94/100\n",
      "4258/4258 [==============================] - 0s 39us/step - loss: 0.2907 - acc: 0.8819\n",
      "Epoch 95/100\n",
      "4258/4258 [==============================] - 0s 46us/step - loss: 0.2911 - acc: 0.8812\n",
      "Epoch 96/100\n",
      "4258/4258 [==============================] - 0s 49us/step - loss: 0.2909 - acc: 0.8802\n",
      "Epoch 97/100\n",
      "4258/4258 [==============================] - 0s 28us/step - loss: 0.2908 - acc: 0.8812\n",
      "Epoch 98/100\n",
      "4258/4258 [==============================] - 0s 64us/step - loss: 0.2905 - acc: 0.8809\n",
      "Epoch 99/100\n",
      "4258/4258 [==============================] - 0s 44us/step - loss: 0.2910 - acc: 0.8812\n",
      "Epoch 100/100\n",
      "4258/4258 [==============================] - 0s 48us/step - loss: 0.2905 - acc: 0.8819\n",
      "4258/4258 [==============================] - 0s 82us/step\n",
      "\n",
      " ********************************** \n",
      "\n",
      "[0.29015027702610613, 0.8821042743071865]\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal', input_dim=17))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(x_train,y_train, batch_size=64, epochs=100)\n",
    "eval_model=classifier.evaluate(x_train, y_train)\n",
    "print(\"\\n ********************************** \\n\")\n",
    "print(eval_model)\n",
    "y_pred=classifier.predict(x_test)\n",
    "y_pred =(y_pred>0.5)\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************************** \n",
      "\n",
      "[[63873 10108]\n",
      " [   58   504]]\n",
      "\n",
      " ********************************** \n",
      "\n",
      "504/562(89.68%) were correctly identified as bots\n",
      "10108/73981 (13.66%) were wrongly identified as bots\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ********************************** \\n\")\n",
    "print(cm)\n",
    "\n",
    "tn = cm[0,0]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "tp = cm[1,1]\n",
    "\n",
    "print(\"\\n ********************************** \\n\")\n",
    "\n",
    "print_perc(tn,tp,fn,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
